# -*- coding: utf-8 -*-
"""Submission MLT-2..ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ABXBmPjMIqliHPUAVieu6ayIeGRI40tN

# Download Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# menyambungkan GDrive
from google.colab import drive
drive.mount('/content/gdrive')

# mengonfigurasikan posisi file kaggle.json
import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"

# mengubah lokasi saat ini ke lokasi konfigurasi
# %cd /content/gdrive/My Drive/Kaggle

# download dataset pada kaggle
!kaggle datasets download -d arashnic/book-recommendation-dataset

# mengekstrak file zip dan menghapus file zip tersebut
!unzip \*.zip  && rm *.zip

"""# Data Understanding & Preparation
Dataset yang digunakan dapat di-download melalui [Kaggle](https://www.kaggle.com/arashnic/book-recommendation-dataset).
"""

# import library yang umum digunakan
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## Book
File ini berisikan 8 kolom yang memiliki 271.379  sampel data. Detail dari masing-masing kolom dapat diuraikan sebagai berikut:
- `ISBN`, merupakan kode pengidentifikasian suatu buku.
- `Book-Title`, merupakan judul dari buku terkait.
- `Book-Author`, merupakan penulis dari buku terkait.
- `Year-Of-Publication`, merupakan tahun keluaran dari buku terkait.
- `Publisher`, merupakan pencetak dari buku terkait.
- `Image-URL-S`, merupakan link URL dari buku terkait berukuran kecil (small).
- `Image-URL-M`, merupakan link URL dari buku terkait berukuran kecil (medium).
- `Image-URL-L`, merupakan link URL dari buku terkait berukuran kecil (large).
"""

# load data buku
df_book = pd.read_csv('Books.csv')

# lihat datanya
df_book.head()

# melihat informasi dataset
df_book.info()

""">**Pembahasan:** <br>
Pada output di atas dapat diketahui bahwa terdapat nilai yang kosong pada beberapa kolom. Sebenarnya data URL gambarnya tidak diperlukan dan tidak ada kepentingannya sama sekali sehingga dapat dihapus.
"""

# hapus kolom gambar
df_book.drop(columns=["Image-URL-S","Image-URL-M","Image-URL-L"], inplace=True)

# lihat datanya
df_book.head()

# mengecek nilai yang kosong
df_book.isnull().sum()

""">**Pembahasan:** <br>
Terdapat 2 kolom yang memiliki nilai yang kosong yaitu `Book-Author` dan `Publisher`. Namun difokuskan untuk menangani kolom `Book-Author` saja karena pada output rekomendasi diharapkan untuk menampilkan judul dan penulis bukunya.
"""

# cek data mana yang kosong
df_book[df_book['Book-Author'].isnull()]

""">**Pembahasan:** <br>
Data penulis yang hilang terdapat pada judul buku `The Credit Suisse Guide to Managing Your Personal Wealth`. Setelah dilakukan pengecekan manual ternyata penulis bukunya ialah `Larissa Anne Downes` sehingga datanya dapat diperbaiki terlebih dahulu sebelum digunakan lebih lanjut.
"""

df_book['Book-Author'][187689] = 'Larissa Anne Downes'

# cek ulang apakah sudah terisi
df_book.isnull().sum()

"""## Rating
File ini berisikan 3 kolom yang memiliki 1.149.780  sampel data. Detail dari masing-masing kolom dapat diuraikan sebagai berikut:
- `User-ID`, merupakan id pembaca.
- `ISBN`, merupakan kode pengidentifikasian suatu buku.
- `Book-Rating`, merupakan rating dari buku yang dinilai oleh pembaca.
"""

# load data rating
df_rating = pd.read_csv('Ratings.csv')

# lihat datanya
df_rating.head()

# melihat informasi dataset
df_rating.info()

""">**Pembahasan:** <br>
Tidak terdapat kesalahan apapun pada informasi output di atas sehingga tidak perlu dilakukan perubahan apapun.
"""

# lihat data yang kosong
df_rating.isnull().sum()

# lihat distribusi nilai rating
df_rating['Book-Rating'].value_counts().sort_values()

""">**Pembahasan:** <br>
Pada output terdapat sesuatu yang sedikit membingungkan yaitu terdapat nilai `0` pada nilai rating. Dapat terpikirkan asumsi bahwa pengguna memiliki buku tetapi belum selesai membacanya atau sudah selesai membaca tapi belum memberikan rating. Karena disini akan dibuat sistem rekomendasi menggunakan data rating yang tentunya memiliki kemiripan terhadap buku yang telah dibaca. Tentunya akan berfokus pada data dengan rating yang jelas. Sehingga, nilai dengan rating `0` akan di-abaikan.
"""

# cek ukuran data
len(df_rating)

# mengabaikan data dengan rating 0
df_rating = df_rating[df_rating['Book-Rating'] != 0]

# cek ukuran data kembali
len(df_rating)

# ubah id user menjadi list tanpa nilai yang sama
user_ids = df_rating['User-ID'].unique().tolist()
# print('list userID: ', user_ids)
 
# encoding id user
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
# print('encoded userID : ', user_to_user_encoded)
 
# proses encoding angka ke ke id user
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
# print('encoded angka ke userID: ', user_encoded_to_user)

# ubah isbn menjadi list tanpa nilai yang sama
book_ids = df_rating['ISBN'].unique().tolist()
# print('list bookID: ', book_ids)
 
# proses encoding isbn
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}
# print('encoded bookID : ', book_to_book_encoded)
 
# proses encoding angka ke isbn
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}
# print('encoded angka ke bookID: ', book_encoded_to_book)

# ambil dataframe sebelumnya
df = df_rating

# mapping user id ke dataframe
df['user'] = df_rating['User-ID'].map(user_to_user_encoded)
 
# mapping isbn ke dataframe
df['book'] = df_rating['ISBN'].map(book_to_book_encoded)

# ambil jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# ambil jumlah buku
num_book = len(book_encoded_to_book)
print(num_book)
 
# ubah tipe data rating menjadi float
df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)
 
# ambil nilai rating terkecil
min_rating = min(df['Book-Rating'])
 
# ambil nilai rating tertinggi
max_rating = max(df['Book-Rating'])
 
print('Number of User: {}, Number of Book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

# acak datasetnya
df = df.sample(frac=1, random_state=42)
df

# pilih data fitur/independen
x = df[['user', 'book']].values
 
# pilih rating sebagai label/output/dependen
y = df['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# bagi menjadi 80% data latih dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""# Modeling"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class RecommenderNet(tf.keras.Model):
  # menggunakan teknik embedding untuk menghitung kecocokan data user dan buku
  # insialisasi constructor
  def __init__(self, num_users, num_book, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_book = num_book
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_book,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_book, 1) # layer embedding book bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    book_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    book_bias = self.book_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
 
    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_book, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 16,
    epochs = 30,
    steps_per_epoch = 300,
    # validation_steps = 50,
    validation_data = (x_val, y_val)
)

"""# Evaluation"""

# lihat visualisasi metrik model
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

""">**Pembahasan:** <br>
Nilai error pada data latih dan validasi model memiliki nilai yang relatif sama. Bahkan pada iterasi terakhir memiliki nilai error yang persis sama yaitu `0.2246`. Nilai tersebut cukup baik untuk pemodelan sistem rekomendasi.
"""

# menghubungkan data rating dengan buku dengan kolom ISBN
df_mix = pd.merge(df_rating, df_book, on='ISBN')

# hapus data ISBN yang kembar sehingga hanya memiliki nilai yang unik saja
df_mix.drop_duplicates('ISBN', inplace=True)

# ambil data kolom ISBN menjadi dalam bentuk list
book_id = df_mix['ISBN'].tolist()
 
# ambil data kolom title menjadi dalam bentuk list
book_title = df_mix['Book-Title'].tolist()
 
# ambil data kolom author menjadi dalam bentuk list
book_author = df_mix['Book-Author'].tolist()

# cek ukuran datanya
print(len(book_id))
print(len(book_title))
print(len(book_author))

# buat dataframe khusus dengan list sebelumnya
book_df = pd.DataFrame({
    'ISBN': book_id,
    'title': book_title,
    'author': book_author
})

book_df.head()

# ambil sampel salah satu user
user_id = df_rating['User-ID'].sample(1).iloc[0]

# data buku yang dibaca user
book_read_by_user = df_rating[df_rating['User-ID'] == user_id]
 
# filter data yang belum pernah dibaca user
book_not_read = book_df[~book_df['ISBN'].isin(book_read_by_user['ISBN'].values)]['ISBN'] 
book_not_read = list(
    set(book_not_read)
    .intersection(set(book_to_book_encoded.keys()))
)
 
book_not_read = [[book_to_book_encoded.get(x)] for x in book_not_read]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_read), book_not_read)
)

# prediksi kecocokan terhadap buku yang telah dibaca
ratings = model.predict(user_book_array).flatten()

# 10 hasi prediksi terbaik
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(book_not_read[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Book with high ratings from user')
print('----' * 8)
 
top_book_user = (
    book_read_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(10)['ISBN'].values
)

book_df_rows = book_df[book_df['ISBN'].isin(top_book_user)]
for row in book_df_rows.itertuples():
    print(f'{row.title} : {row.author}')

print('----' * 8)
print('Top 10 book recommendation')
print('----' * 8)
 
recommended_book = book_df[book_df['ISBN'].isin(recommended_book_ids)]
for row in recommended_book.itertuples():
    print(f'{row.title} : {row.author}')

""">**Pembahasan:** <br>
Dari output hasil rekomendasi terhadap pengguna di atas, dapat terlihat kesesuaian dari rekomendasi yang diberikan, sebab terlihat pengguna pernah membaca buku Harry Potter kemudian sistem merekomendasikan untuk membaca buku Harry Potter lainnya.
"""